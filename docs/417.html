<html>
<head>
<title>How To Install Hadoop On Ubuntu 20.04 LTS [Focal Fossa] - Eldernode</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>如何在Ubuntu 20.04上安装Hadoop LTS[Focal Fossa]-elder node</h1>
<blockquote>原文：<a href="https://blog.eldernode.com/install-hadoop-on-ubuntu-20-04/#0001-01-01">https://blog.eldernode.com/install-hadoop-on-ubuntu-20-04/#0001-01-01</a></blockquote><div><div class="blog-details">                                  <img data-lazyloaded="1" src="../Images/c580747c2278819e02124e297c4df731.png" data-src="https://blog.eldernode.com/wp-content/uploads/2020/11/How-To-Install-Hadoop-On-Ubuntu-20.04-LTS-Focal-Fossa.png" class="img-fluid mb-3 shadow-sm round-10 wp-post-image" alt="How To Install Hadoop On Ubuntu 20.04 LTS [Focal Fossa]" decoding="async" data-srcset="https://blog.eldernode.com/wp-content/uploads/2020/11/How-To-Install-Hadoop-On-Ubuntu-20.04-LTS-Focal-Fossa.png 2069w, https://blog.eldernode.com/wp-content/uploads/2020/11/How-To-Install-Hadoop-On-Ubuntu-20.04-LTS-Focal-Fossa-300x164.png 300w, https://blog.eldernode.com/wp-content/uploads/2020/11/How-To-Install-Hadoop-On-Ubuntu-20.04-LTS-Focal-Fossa-1024x561.png 1024w, https://blog.eldernode.com/wp-content/uploads/2020/11/How-To-Install-Hadoop-On-Ubuntu-20.04-LTS-Focal-Fossa-768x421.png 768w, https://blog.eldernode.com/wp-content/uploads/2020/11/How-To-Install-Hadoop-On-Ubuntu-20.04-LTS-Focal-Fossa-1536x842.png 1536w, https://blog.eldernode.com/wp-content/uploads/2020/11/How-To-Install-Hadoop-On-Ubuntu-20.04-LTS-Focal-Fossa-2048x1122.png 2048w" data-sizes="(max-width: 2069px) 100vw, 2069px" data-original-src="https://blog.eldernode.com/wp-content/uploads/2020/11/How-To-Install-Hadoop-On-Ubuntu-20.04-LTS-Focal-Fossa.png"/><p>了解如何<strong>一步步在Ubuntu 20.04 LTS </strong>上安装Hadoop。Hadoop是一个基于java的数据框架。这款开源软件为任何类型的数据提供了海量存储、强大的处理能力，以及处理几乎无限的并发任务或工作的能力。购买您自己的<a href="https://eldernode.com/ubuntu-vps/" target="_blank" rel="noopener noreferrer"> Ubuntu VPS </a>并加入我们这篇文章，开始了解它并享受Hadoop最重要的能力，快速存储和处理大量的任何类型的数据。</p><p>如果您考虑以下<strong>先决条件:</strong>，本教程可能会更有用</p><p><strong> 1- </strong>运行Ubuntu 20.04的服务器。</p><div class="uncode_text_column"><p><strong> 2- </strong>本地/远程机器上的Sudo或root权限</p><p><strong> 3- </strong> 16GB内存/8vCPU/20GB引导磁盘/100GB原始磁盘，用于数据存储</p><div class="text parbase section"><div class=""><h2><span class="ez-toc-section" id="Tutorial_Install_Hadoop_On_Ubuntu_2004_LTS"/>教程在Ubuntu 20.04 LTS上安装Hadoop<span class="ez-toc-section-end"/></h2><p>Hadoop以其计算能力而闻名。当你使用它的时候，你明白你使用的计算节点越多，你的处理能力就越强。通过处理从公司收集的数据，Hadoop可以推断出未来的决策结果。</p></div></div></div><h2><span class="ez-toc-section" id="Install_And_Configure_Apache_Hadoop_On_Ubuntu_2004"/>在Ubuntu 20.04上安装和配置Apache Hadoop<span class="ez-toc-section-end"/></h2><p>让我们通过本教程的10个步骤来完成对Hadoop的学习。</p><div class="contributeEdit"><h3 id="tocContainer"><span class="ez-toc-section" id="Step_1_How_To_Install_Java"/>第一步:如何安装Java <span class="ez-toc-section-end"/></h3><p>由于Hadoop是用<a href="https://blog.eldernode.com/install-java-apt-ubuntu-20/" target="_blank" rel="noopener noreferrer"> Java </a>编写的，所以可以在更新系统后从默认的apt仓库安装OpenJDK 8:</p></div><div><pre><code class="language-bash">sudo apt update</code></pre><div><pre><code class="language-bash">sudo apt install openjdk-8-jd</code></pre></div></div><p class="code-toolbar">注意:Hadoop支持Java版本8</p><p>运行以下命令检查Java的安装版本:</p><pre><code class="language-bash">java -version</code></pre><h3><span class="ez-toc-section" id="Step_2_How_To_Create_A_Hadoop_User"/>步骤2:如何创建Hadoop用户<span class="ez-toc-section-end"/></h3><p>考虑到<a href="https://blog.eldernode.com/tag/security/" target="_blank" rel="noopener noreferrer">安全</a>的原因，建议您创建一个单独的用户来运行Hadoop。为此，键入以下名为Hadoop的命令:</p><pre><code class="language-bash">sudo adduser hadoop</code></pre><h3><span class="ez-toc-section" id="Step_3_How_To_Configure_SSH_key-based_Authentication"/>步骤3:如何配置基于SSH密钥的认证<span class="ez-toc-section-end"/></h3><p>在此步骤中，您需要为本地系统配置无密码SSH验证。因此，使用您在上面的步骤中创建的用户<strong> hadoop </strong>登录，并运行下面的命令:</p><pre><code class="language-bash">su - hadoop</code></pre><p>要生成公钥和私钥对，请键入:</p><pre><code class="language-bash">ssh-keygen -t rsa</code></pre><div><pre><code class="language-bash">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code></pre></div><div><pre><code class="language-bash">chmod 640 ~/.ssh/authorized_keys</code></pre></div><div><p>然后，使用以下命令验证无密码SSH身份验证:</p></div><h3><span class="ez-toc-section" id="Step_4_Install_Hadoop_On_Ubuntu_2004"/>第四步:在Ubuntu 20.04上安装Hadoop<span class="ez-toc-section-end"/></h3><p>确保使用用户<strong> hadoop </strong>登录后，运行以下命令</p><pre><code class="language-bash">su - hadoop</code></pre><p>要下载最新版本的Hadoop，请键入:</p><p>下载完成后，使用以下命令提取下载的文件:</p><pre><code class="language-bash">tar -xvzf hadoop-3.3.0.tar.gz</code></pre><p>使用以下命令将提取的目录重命名为hadoop:</p><p>要在系统上配置Hadoop和Java环境变量，请打开文件~/。bashrcin在您最喜欢的文本编辑器中:</p><pre><code class="language-bash">nano ~/.bashrc</code></pre><p>然后，添加以下几行:</p><div><pre><code class="language-bash">export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64/  export HADOOP_HOME=/home/hadoop/hadoop  export HADOOP_INSTALL=$HADOOP_HOME  export HADOOP_MAPRED_HOME=$HADOOP_HOME  export HADOOP_COMMON_HOME=$HADOOP_HOME  export HADOOP_HDFS_HOME=$HADOOP_HOME  export HADOOP_YARN_HOME=$HADOOP_HOME  export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native  export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin  export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"</code></pre></div><p>现在，您可以保存并关闭文件。</p><p>要激活环境变量，请运行:</p><pre><code class="language-bash">source ~/.bashrc</code></pre><p>然后，打开Hadoop环境变量文件:</p><div><pre><code class="language-bash">nano $HADOOP_HOME/etc/hadoop/hadoop-env.sh</code></pre></div><p>根据JAVA安装路径，取消注释并更改变量JAVA _:</p><div><pre><code class="language-bash">export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64/</code></pre></div><p>现在，完成后您可以保存并关闭文件。</p><h3><span class="ez-toc-section" id="Step_5_How_To_Configure_Hadoop"/>第5步:如何配置Hadoop <span class="ez-toc-section-end"/></h3><p>要创建这两个目录，请运行:</p><pre><code class="language-bash">mkdir -p ~/hadoopdata/hdfs/namenode</code></pre><div><pre><code class="language-bash">mkdir -p ~/hadoopdata/hdfs/datanode</code></pre></div><p>然后，您可以编辑文件core-site.xml并使用您的系统主机名进行更新:</p><pre><code class="language-bash">nano $HADOOP_HOME/etc/hadoop/core-site.xml</code></pre><p>接下来，您应该编辑以下文件以匹配系统的主机名:</p><pre class="code-toolbar"><code class="language-bash">&lt;configuration&gt;          &lt;property&gt;                 &lt;name&gt;fs.defaultFS&lt;/name&gt;                 &lt;value&gt;hdfs://example.com:9000&lt;/value&gt;          &lt;/property&gt;  &lt;/configuration&gt;</code></pre><p>现在，您可以保存并关闭文件。然后，编辑文件<strong> hdfs-site.xml </strong>:</p><pre class="code-toolbar"><code class="language-bash">nano $HADOOP_HOME/etc/hadoop/hdfs-site.xml</code></pre><p>目录路径<strong> NameNode </strong>和<strong> DataNode </strong>应该修改如下:</p><pre><code class="language-bash">&lt;configuration&gt;             &lt;property&gt;                  &lt;name&gt;dfs.replication&lt;/name&gt;                  &lt;value&gt;1&lt;/value&gt;          &lt;/property&gt;             &lt;property&gt;                  &lt;name&gt;dfs.name.dir&lt;/name&gt;                  &lt;value&gt;file:///home/hadoop/hadoopdata/hdfs/namenode&lt;/value&gt;          &lt;/property&gt;             &lt;property&gt;                  &lt;name&gt;dfs.data.dir&lt;/name&gt;                  &lt;value&gt;file:///home/hadoop/hadoopdata/hdfs/datanode&lt;/value&gt;          &lt;/property&gt;  </code></pre><p>现在，您可以保存并关闭文件。然后，编辑文件<strong> mapred-site.xml </strong>:</p><div><pre><code class="language-bash">nano $HADOOP_HOME/etc/hadoop/mapred-site.xml</code></pre></div><p>进行以下更改:</p><div><pre><code class="language-bash">&lt;configuration&gt;          &lt;property&gt;                  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;                  &lt;value&gt;yarn&lt;/value&gt;          &lt;/property&gt;  &lt;/configuration&gt;</code></pre></div><p>现在，您可以保存并关闭文件。然后，编辑y文件<strong> arn-site.xml </strong>:</p><div><pre><code class="language-bash">nano $HADOOP_HOME/etc/hadoop/yarn-site.xml</code></pre></div><p>最后，进行以下更改:</p><div><pre><code class="language-bash">&lt;configuration&gt;          &lt;property&gt;                  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;                  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;          &lt;/property&gt;  &lt;/configuration&gt;</code></pre></div><p>现在，完成后您可以保存并关闭文件。</p><h3><span class="ez-toc-section" id="Step_6_How_To_Start_Hadoop_Cluster"/>第六步:如何启动Hadoop集群<span class="ez-toc-section-end"/></h3><p>首先，您应该将Namenode格式化为<strong> hadoop </strong>用户。使用下面的命令来完成此操作:</p><pre><code class="language-bash">hdfs namenode -format</code></pre><p>要启动<strong> hadoop </strong>集群，运行:</p><pre><code class="language-bash">start-dfs.sh</code></pre><p>然后，键入以下命令来启动服务<strong> YARN </strong></p><pre><code class="language-bash">start-yarn.sh</code></pre><p>使用下面的命令检查所有服务的状态<strong> Hadoop </strong></p><pre><code class="language-bash">jps</code></pre><h3 id="configurare-il-firewall"><span class="ez-toc-section" id="Step_7_How_To_Configure_the_firewall"/>第七步:如何配置防火墙<span class="ez-toc-section-end"/></h3><p>通过运行以下命令，允许Hadoop连接通过防火墙:</p><pre><code class="language-bash">ufw allow 9870/tcp</code></pre><pre><code class="language-bash">ufw allow 8088/tcp</code></pre><h3 id="accedere-a-hadoop-namenode-e-resource-manager"><span class="ez-toc-section" id="Step_8_How_To_Log_in_To_Hadoop_Namenode_And_Resource_Manager"/>步骤8:如何登录Hadoop Namenode和资源管理器<span class="ez-toc-section-end"/></h3><p>您可以访问网址“http://example.com:9870”来访问Namenode。在那里，您可以看到服务摘要屏幕。</p><p>此外，要访问资源管理，您应该访问URL“http://example . com:8088”以查看Hadoop管理屏幕。</p><h3><span class="ez-toc-section" id="Step_9_How_To_Check_Hadoop_Cluster"/>第九步:如何检查Hadoop集群<span class="ez-toc-section-end"/></h3><p>虽然Hadoop集群已经安装并配置完毕，但是您需要在HDFS文件系统中创建一些目录来测试Hadoop。</p><p><em>注意</em>:请确保使用用户<strong> hadoop </strong>登录</p><pre><code class="language-bash">su - hadoop</code></pre><p>使用以下命令在HDFS文件系统中创建一个目录:</p><pre><code class="language-bash">hdfs dfs -mkdir /test1</code></pre><pre><code class="language-bash">hdfs dfs -mkdir /logs</code></pre><p>要列出上面的目录，请键入:</p><p>然后尝试把一些文件放到hadoop的文件系统中。您可以将主机上的日志文件添加到hadoop文件系统中。</p><pre><code class="language-bash">hdfs dfs -put /var/log/* /logs/</code></pre><p>注意:如果您需要检查上述文件和目录，您可以在Hadoop Namenode web界面中完成。</p><p>进入Namenode web界面，点击<strong>工具- &gt;浏览文件系统</strong>。您应该会看到您之前创建的目录。</p><h3><span class="ez-toc-section" id="Step_10_How_To_Stop_Hadoop_Cluster"/>第十步:如何停止Hadoop集群<span class="ez-toc-section-end"/></h3><p>您需要作为Hadoop用户运行<strong> stop-dfs.sh </strong>和<strong> stop-yarn.sh </strong>脚本，以便能够停止Hadoop Namenode和yarn服务</p><p>运行以下命令停止Hadoop Namenode服务:</p><pre><code class="language-bash">stop-dfs.sh</code></pre><p>要停止Hadoop资源管理器服务，请键入:</p><pre><code class="language-bash">stop-yarn.sh</code></pre><p> </p><h2><span class="ez-toc-section" id="Conclusion"/>结论<span class="ez-toc-section-end"/></h2><p>在本文中，您已经学习了如何在Ubuntu 20.04 LTS上安装Hadoop。由于您的业务需求的种类，您可以通过在您的组织中采用这种技术来使用它在当今生活中的重要作用，因为它适用于任何领域。</p></div></div>    
</body>
</html>